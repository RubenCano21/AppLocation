# Descentralizaci√≥n del Timestamp - Documentaci√≥n

## üìã Resumen

Se implement√≥ la descentralizaci√≥n del campo `timestamp` para separar la fecha y la hora en campos independientes, permitiendo an√°lisis dimensional del tiempo.

## üéØ Objetivo

Transformar los datos de ubicaci√≥n de Supabase (producci√≥n) sin modificar la BD de origen, extrayendo y clasificando informaci√≥n temporal para facilitar an√°lisis por periodos del d√≠a.

## üîÑ Flujo ETL

### 1. **Extracci√≥n** (Supabase - Producci√≥n)
- Se conecta via API REST a Supabase
- Extrae datos de la tabla de ubicaciones
- **NO modifica** nada en producci√≥n

### 2. **Transformaci√≥n** (PySpark)
El campo `timestamp` se descentraliza en:

| Campo Nuevo | Tipo | Descripci√≥n | Ejemplo |
|------------|------|-------------|---------|
| `date` | Date | Fecha sin hora | `2025-12-03` |
| `hour_value` | Integer | Hora del d√≠a (0-23) | `14` |
| `time_period` | String | Periodo del d√≠a | `TARDE` |
| `time_period_code` | String | C√≥digo corto del periodo | `AFT` |
| `time_id` | Integer | FK a dim_time | `14` |

#### Clasificaci√≥n de Periodos

```python
MA√ëANA (MOR):  06:00 - 11:59
TARDE  (AFT):  12:00 - 18:59
NOCHE  (NIG):  19:00 - 05:59
```

### 3. **Carga** (PostgreSQL - Destino)
- Los datos transformados se cargan en PostgreSQL
- La tabla `locations` incluye todos los campos nuevos
- Se crean √≠ndices para optimizar consultas por tiempo

## üìÅ Archivos Modificados

### 1. `app/spark/transformations.py`
```python
# Nuevas transformaciones agregadas:
- Conversi√≥n de timestamp a formato datetime
- Extracci√≥n de fecha (date)
- Extracci√≥n de hora (hour_value)
- Clasificaci√≥n en periodos (time_period)
- Generaci√≥n de c√≥digos (time_period_code)
- Creaci√≥n de time_id para FK
```

### 2. `app/models/db_models.py`
```python
# Campos agregados a la clase Location:
date = Column(DateTime, index=True)
hour_value = Column(Integer)
time_period = Column(String(20))
time_period_code = Column(String(10))
time_id = Column(Integer, index=True)
```

### 3. `app/services/etl_service.py`
```python
# Actualizado el select para incluir nuevos campos:
.select(
    ...,
    "date", "hour_value", "time_period", 
    "time_period_code", "time_id",
    ...
)
```

## üóÉÔ∏è Esquema de Base de Datos

### Tabla: dim_time (Dimensi√≥n)
```sql
CREATE TABLE dim_time (
    id INTEGER PRIMARY KEY,        -- 0-23
    hour INTEGER NOT NULL,
    period VARCHAR(20),            -- MA√ëANA, TARDE, NOCHE
    period_code VARCHAR(10)        -- MOR, AFT, NIG
);
```

### Tabla: locations (Hechos)
```sql
ALTER TABLE locations ADD COLUMN date TIMESTAMP;
ALTER TABLE locations ADD COLUMN hour_value INTEGER;
ALTER TABLE locations ADD COLUMN time_period VARCHAR(20);
ALTER TABLE locations ADD COLUMN time_period_code VARCHAR(10);
ALTER TABLE locations ADD COLUMN time_id INTEGER;

CREATE INDEX idx_locations_date ON locations(date);
CREATE INDEX idx_locations_time_id ON locations(time_id);
```

## üöÄ Uso

### Ejecutar el ETL Completo
```python
from app.services.etl_service import ETLService

etl = ETLService()
result = await etl.run_full_etl()
```

### Poblar Dimensi√≥n de Tiempo
```python
from app.services.dimension_service import DimensionService
from app.database.postgres_db import get_db

db = next(get_db())
DimensionService.populate_dim_time(db)
```

### Ejecutar Migraci√≥n SQL
```bash
psql -h localhost -U postgres -d location_db -f migrations/add_timestamp_fields.sql
```

## üß™ Pruebas

### Ejecutar Test de Transformaci√≥n
```bash
python tests/test_timestamp_transformation.py
```

Este test valida:
- ‚úÖ Extracci√≥n correcta de fecha
- ‚úÖ Extracci√≥n correcta de hora (0-23)
- ‚úÖ Clasificaci√≥n correcta en MA√ëANA/TARDE/NOCHE
- ‚úÖ Generaci√≥n correcta de c√≥digos MOR/AFT/NIG
- ‚úÖ Creaci√≥n correcta de time_id

## üìä Consultas de Ejemplo

### An√°lisis por Periodo del D√≠a
```sql
SELECT 
    time_period,
    COUNT(*) as total_locations,
    AVG(battery) as avg_battery,
    AVG(signal) as avg_signal
FROM locations
GROUP BY time_period
ORDER BY time_period;
```

### An√°lisis por Hora del D√≠a
```sql
SELECT 
    hour_value,
    time_period,
    COUNT(*) as registros,
    COUNT(DISTINCT device_id) as dispositivos_unicos
FROM locations
GROUP BY hour_value, time_period
ORDER BY hour_value;
```

### Join con Dimensi√≥n de Tiempo
```sql
SELECT 
    l.date,
    t.hour,
    t.period,
    COUNT(*) as registros
FROM locations l
JOIN dim_time t ON l.time_id = t.id
GROUP BY l.date, t.hour, t.period
ORDER BY l.date, t.hour;
```

## üîç Verificaci√≥n

### Datos Originales en Supabase
```
timestamp: "2025-12-03 14:30:00"
```

### Datos Transformados en PostgreSQL
```
timestamp: "2025-12-03 14:30:00"
date: "2025-12-03"
hour_value: 14
time_period: "TARDE"
time_period_code: "AFT"
time_id: 14
```

## ‚ö†Ô∏è Notas Importantes

1. **No Modificaci√≥n de Producci√≥n**: La BD de Supabase NO se modifica
2. **Datos Hist√≥ricos**: Si ya tienes datos en PostgreSQL, usa el UPDATE en `migrations/add_timestamp_fields.sql`
3. **Timezone**: Los timestamps se procesan en UTC por defecto
4. **√çndices**: Se crean autom√°ticamente para optimizar consultas

## üìà Beneficios

‚úÖ **An√°lisis temporal m√°s eficiente**: Consultas por periodo del d√≠a  
‚úÖ **Modelo dimensional**: Integraci√≥n con dim_time  
‚úÖ **Performance**: √çndices optimizados para queries temporales  
‚úÖ **Flexibilidad**: Mantiene timestamp original + campos descentralizados  
‚úÖ **Sin impacto en producci√≥n**: Transformaci√≥n solo en destino  

## üîó Pr√≥ximos Pasos

1. Ejecutar migraci√≥n SQL en PostgreSQL destino
2. Poblar dim_time con `DimensionService.populate_dim_time()`
3. Ejecutar ETL para cargar datos con nuevos campos
4. Validar con consultas de ejemplo
5. Crear dashboards por periodo del d√≠a

---
**Fecha**: 2025-12-03  
**Versi√≥n**: 1.0  
**Autor**: Sistema ETL AppLocation

